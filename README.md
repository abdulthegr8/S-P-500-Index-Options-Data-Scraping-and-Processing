# S-P-500-Index-Options-Data-Scraping-and-Processing
Project Overview:
In this project, I used Selenium WebDriver, Pandas, and openpyxl to scrape S&P 500 Index options data from the Barchart website. The purpose of this project was to retrieve the data on the put and call volume, open interest, and average at-the-money volatility for different expiration dates. The data was then processed, cleaned, and saved to an Excel file.

Project Implementation:
I used Selenium WebDriver to automate the process of opening the website and retrieving the data. The data was then stored in variables and processed using Pandas. The processed data was then saved to an Excel file using openpyxl. I faced some challenges while scraping the data, such as handling the dynamic nature of the website, but I was able to overcome these challenges through trial and error.

Results:
The results of the project were a clean and organized data set that could be used for further analysis. The data includes information on the put and call volume, open interest, and average at-the-money volatility for different expiration dates. The data was saved in an Excel file for easy access and future use.

Skills Demonstrated:
This project demonstrates my abilities in web scraping, data processing, and Python programming. I utilized Selenium WebDriver to automate the process of opening the website and retrieving the data, Pandas to process and clean the data, and openpyxl to save the data to an Excel file.

Source Code:
The source code for this project is available here on my GitHub account.

In conclusion, this project showcases my skills in web scraping, data processing, and Python programming. I was able to successfully retrieve and process the S&P 500 Index options data, demonstrating my ability to work with dynamic websites and my understanding of data processing techniques.
